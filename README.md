# AI-Based Genetic Mutation Prioritization

## Abstract

This project implements an AI-driven approach for prioritizing genetic mutations, specifically focusing on distinguishing pathogenic variants from benign ones. It leverages deep learning models (MLP), ensemble methods (stacking), uncertainty quantification (MC Dropout, Bayesian ranking), and gene-level aggregation to achieve robust and interpretable predictions.

---

## ğŸ¯ Key Features

- **Deep Learning Models**: MLP with configurable architecture, dropout, and batch normalization
- **Baseline Models**: Logistic regression for performance comparison
- **Ensemble Learning**: Stacking with multiple base learners and meta-learner
- **Uncertainty Quantification**: MC Dropout for epistemic uncertainty estimation
- **Bayesian Ranking**: Confidence-aware variant prioritization with credible intervals
- **Gene-Level Aggregation**: Variant-to-gene score aggregation for biological interpretation
- **Reproducibility**: Centralized seed management and deterministic mode
- **Config-Driven**: Single YAML configuration file controls all experiments

---

## ğŸ“ Project Structure

```
AI-Based-approach-for-prioritization-of-genetic-mutations/
â”‚
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â””â”€â”€ config.yaml              # Single source of truth for all parameters
â”‚
â”œâ”€â”€ data/                        # Data storage (strict lifecycle: RAW â†’ INTERIM â†’ PROCESSED)
â”‚   â”œâ”€â”€ raw/                     # âŒ READ-ONLY: Original datasets (VCF, CSV)
â”‚   â”‚   â”œâ”€â”€ clinvar_input.vcf
â”‚   â”‚   â”œâ”€â”€ mutation_impact_dataset.csv
â”‚   â”‚   â””â”€â”€ labels.csv
â”‚   â”œâ”€â”€ interim/                 # âš™ï¸ DERIVED: Engineered features (not preprocessed)
â”‚   â”‚   â””â”€â”€ feature_matrix_raw.csv
â”‚   â””â”€â”€ processed/               # âœ… TRAINING-READY: Preprocessed features
â”‚       â”œâ”€â”€ feature_matrix_processed.csv
â”‚       â””â”€â”€ preprocessor.joblib
â”‚
â”œâ”€â”€ notebooks/                   # Experimentation workflows â­ START HERE!
â”‚   â”œâ”€â”€ 00_data_pipeline.ipynb           # âš ï¸ RUN FIRST: RAW â†’ INTERIM â†’ PROCESSED
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb         # EDA and feature analysis
â”‚   â”œâ”€â”€ 02_baseline_training.ipynb        # Logistic regression baseline
â”‚   â”œâ”€â”€ 03_mlp_training.ipynb             # Deep learning training
â”‚   â”œâ”€â”€ 04_ensemble_training.ipynb        # Stacking ensemble
â”‚   â”œâ”€â”€ 05_uncertainty_analysis.ipynb     # MC Dropout + Bayesian ranking
â”‚   â””â”€â”€ 06_gene_level_ranking.ipynb       # Gene aggregation
â”‚
â”œâ”€â”€ src/                         # Source code (import from here!)
â”‚   â”œâ”€â”€ models/                  # Model architectures (NO training logic)
â”‚   â”‚   â”œâ”€â”€ baseline.py          # LogisticRegression
â”‚   â”‚   â”œâ”€â”€ mlp.py              # Multi-layer perceptron
â”‚   â”‚   â””â”€â”€ gnn.py              # Graph neural network
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/           # Data processing
â”‚   â”‚   â”œâ”€â”€ data_loader.py      # DataLoader creation
â”‚   â”‚   â”œâ”€â”€ preprocessing.py    # Feature engineering
â”‚   â”‚   â”œâ”€â”€ dataset.py          # PyTorch Dataset
â”‚   â”‚   â”œâ”€â”€ validation.py       # Data validation utilities
â”‚   â”‚   â””â”€â”€ pipeline.py         # RAW â†’ INTERIM â†’ PROCESSED pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/              # Metrics and visualization
â”‚   â”‚   â”œâ”€â”€ metrics.py          # ROC-AUC, PR-AUC, F1
â”‚   â”‚   â”œâ”€â”€ plotting.py         # Plotter class
â”‚   â”‚   â”œâ”€â”€ ranking_metrics.py  # Ranking evaluation
â”‚   â”‚   â”œâ”€â”€ reporting.py        # Report generation
â”‚   â”‚   â””â”€â”€ calibration.py      # Calibration analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ uncertainty/             # Uncertainty quantification
â”‚   â”‚   â”œâ”€â”€ mc_dropout.py       # MC Dropout estimator
â”‚   â”‚   â””â”€â”€ bayesian_ranking.py # Bayesian ranker
â”‚   â”‚
â”‚   â”œâ”€â”€ ensemble/                # Ensemble methods
â”‚   â”‚   â””â”€â”€ stacking.py         # Stacking ensemble
â”‚   â”‚
â”‚   â”œâ”€â”€ aggregation/             # Gene-level aggregation
â”‚   â”‚   â””â”€â”€ gene_score.py       # GeneAggregator
â”‚   â”‚
â”‚   â””â”€â”€ utils/                   # Utilities
â”‚       â”œâ”€â”€ seed.py             # Reproducibility (set_seed)
â”‚       â””â”€â”€ config.py           # Config management
â”‚
â”œâ”€â”€ reports/                     # Output storage
â”‚   â”œâ”€â”€ figures/                 # Plots and visualizations
â”‚   â””â”€â”€ results/                 # Metrics, checkpoints, rankings
â”‚       â”œâ”€â”€ checkpoints/         # Model weights (.pth, .joblib)
â”‚       â””â”€â”€ logs/               # Training history (.json)
â”‚
â”œâ”€â”€ tests/                       # Testing utilities
â”‚
â”œâ”€â”€ REFACTORING_SUMMARY.md      # Detailed architectural documentation
â”œâ”€â”€ QUICK_REFERENCE.md          # Quick start guide
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
â”‚   â”œâ”€â”€ interpretation/           # Model explainability
â”‚   â”‚   â””â”€â”€ explainer.py          # SHAP/attention interpretation
â”‚   â”œâ”€â”€ utils/                    # Data utilities
â”‚   â”‚   â”œâ”€â”€ data_loader.py        # PyTorch data loading
â”‚   â”‚   â”œâ”€â”€ dataset.py            # Custom dataset classes
â”‚   â”‚   â”œâ”€â”€ preprocessing.py      # Feature preprocessing
â”‚   â”‚   â””â”€â”€ data_generator.py     # Synthetic data generation
â”‚   â”œâ”€â”€ main.py                   # CLI entry point
â”‚   â”œâ”€â”€ train.py                  # Model training script
â”‚   â”œâ”€â”€ train_ensemble.py         # Ensemble training script
â”‚   â”œâ”€â”€ evaluate.py               # Evaluation script
â”‚   â””â”€â”€ prioritize.py             # Inference/prioritization script
â”‚
â”œâ”€â”€ data/
```

---

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repo_url>
cd AI-Based-approach-for-prioritization-of-genetic-mutations

# Install dependencies
pip install -r requirements.txt
```

### 2. Run Notebooks

Open Jupyter and run the notebooks in order:

```bash
jupyter notebook
```

**Recommended execution order:**
0. [00_data_pipeline.ipynb](notebooks/00_data_pipeline.ipynb) - **âš ï¸ RUN FIRST!** Executes RAW â†’ INTERIM â†’ PROCESSED pipeline
1. [01_data_exploration.ipynb](notebooks/01_data_exploration.ipynb) - Understand your data
2. [02_baseline_training.ipynb](notebooks/02_baseline_training.ipynb) - Establish baseline
3. [03_mlp_training.ipynb](notebooks/03_mlp_training.ipynb) - Train deep learning model
4. [04_ensemble_training.ipynb](notebooks/04_ensemble_training.ipynb) - Combine models
5. [05_uncertainty_analysis.ipynb](notebooks/05_uncertainty_analysis.ipynb) - Quantify uncertainty
6. [06_gene_level_ranking.ipynb](notebooks/06_gene_level_ranking.ipynb) - Generate gene rankings

### 3. Data Lifecycle

This project enforces strict data separation: **RAW â†’ INTERIM â†’ PROCESSED**

```
data/
â”œâ”€â”€ raw/          # âŒ READ-ONLY: Original untouched data
â”œâ”€â”€ interim/      # âš™ï¸ DERIVED: Engineered features (not scaled)
â””â”€â”€ processed/    # âœ… TRAINING-READY: Final processed data
```

**Key Rules**:
- âŒ **NEVER WRITE** to `data/raw/` after initial placement
- âœ… Run `00_data_pipeline.ipynb` to process data
- âœ… All training loads from `data/processed/`
- âœ… Validation enforced automatically

See [DATA_LIFECYCLE.md](DATA_LIFECYCLE.md) for complete documentation.

### 4. Configuration

Edit [configs/config.yaml](configs/config.yaml) to customize:
- Data paths
- Model hyperparameters
- Training settings
- Uncertainty estimation parameters

---

## ğŸ“Š Models and Methods

### 1. Baseline Models
- **Logistic Regression**: Single-layer linear model for binary classification
- Serves as performance baseline for deep learning models

### 2. Deep Learning (MLP)
- **Architecture**: Configurable hidden layers with dropout and batch normalization
- **Training**: Early stopping with validation monitoring
- **Optimization**: Adam optimizer with BCE loss

### 3. Ensemble Learning
- **Method**: Stacking with multiple base learners
- **Base Models**: MLP, XGBoost, LightGBM
- **Meta-Learner**: Logistic Regression
- **Benefit**: Improved robustness and performance

### 4. Uncertainty Quantification
- **MC Dropout**: Bayesian approximation via stochastic forward passes
- **Output**: Predictive mean and variance for each variant
- **Use Case**: Identifying low-confidence predictions

### 5. Bayesian Ranking
- **Method**: Posterior inference with Beta-Binomial conjugate prior
- **Output**: Ranked variants with credible intervals
- **Benefit**: Incorporates uncertainty into prioritization

### 6. Gene-Level Aggregation
- **Methods**: Max, mean, median aggregation
- **Input**: Variant-level scores
- **Output**: Gene-level priority scores
- **Use Case**: Identifying high-risk genes

---

## ğŸ“ˆ Evaluation Metrics

- **ROC-AUC**: Overall discrimination performance
- **PR-AUC**: Performance on imbalanced data
- **F1 Score**: Harmonic mean of precision and recall
- **Confusion Matrix**: Classification breakdown
- **Calibration**: Reliability of predicted probabilities

---

## ğŸ”¬ Research Features

### Reproducibility
```python
from src.utils.seed import set_seed

set_seed(42)  # Ensures reproducible results
```

### Config-Driven Experiments
```python
from src.utils.config import Config

config = Config('configs/config.yaml')
batch_size = config.training['batch_size']
```

### Clean Module Imports
```python
from src.models import MLP, LogisticRegression
from src.preprocessing import get_data_loaders
from src.evaluation import calculate_metrics, Plotter
from src.uncertainty import MCDropoutEstimator, BayesianRanker
```

---

## ğŸ“š Documentation

- **[DATA_LIFECYCLE.md](DATA_LIFECYCLE.md)**: Data pipeline and lifecycle management
- **[REFACTORING_SUMMARY.md](REFACTORING_SUMMARY.md)**: Comprehensive architectural documentation
- **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)**: Quick start guide and API reference

---

## ğŸ§ª Testing

Generate dummy data for testing:
```bash
python tests/create_dummy_data.py
```

---

## ğŸ—ï¸ Architecture Principles

âœ… **Separation of Concerns**: Architecture in `src/`, experiments in `notebooks/`  
âœ… **Config-Driven**: Single source of truth in `configs/config.yaml`  
âœ… **Reproducibility**: Centralized seed management  
âœ… **Modularity**: Clean imports via `__init__.py`  
âœ… **Research-Grade**: Publication-ready code quality  

---

## ğŸ“„ License

See [LICENSE](LICENSE) for details.

---

## ğŸ¤ Contributing

This project follows a clean research architecture. When contributing:
1. Add model architectures to `src/models/` (NO training logic)
2. Create experiments in `notebooks/`
3. Update `configs/config.yaml` for new parameters
4. Ensure reproducibility with `set_seed(42)`

---

## ğŸ“§ Contact

For questions or collaborations, please open an issue on GitHub.

---

**Happy Mutation Prioritizing! ğŸ§¬**

```bash
python src/main.py prioritize data/raw/new_variants.csv --output reports/results/prioritized.csv
```

## Configuration

All hyperparameters, paths, and experiment settings are managed in [src/config/config.yaml](src/config/config.yaml).

The configuration is loaded via the `Config` class in [src/config/loader.py](src/config/loader.py):

```python
from src.config.loader import Config

config = Config("src/config/config.yaml")
print(config.model['type'])  # Access model configuration
print(config.training['epochs'])  # Access training parameters
```

### Key Configuration Sections

- **data**: Feature definitions, paths, preprocessing options
- **model**: Model architecture and hyperparameters
- **training**: Learning rate, batch size, epochs, optimizer settings
- **evaluation**: Metrics, thresholds, calibration parameters
- **ensemble**: Stacking configuration and base learners
- **uncertainty**: MC Dropout settings
- **graph**: GNN architecture and graph construction
- **aggregation**: Gene-level scoring methods
- **ranking**: Bayesian ranking parameters

## License

[License Name]
