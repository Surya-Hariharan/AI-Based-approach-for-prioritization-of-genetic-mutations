{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.utils.seed import set_seed\n",
    "from src.utils.config import Config\n",
    "from src.preprocessing import get_data_loaders\n",
    "from src.models import LogisticRegression\n",
    "from src.evaluation import calculate_metrics, P lotter\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed66960",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config('../configs/config.yaml')\n",
    "train_loader, val_loader, test_loader, input_dim = get_data_loaders(config)\n",
    "\n",
    "print(f\"Input Features: {input_dim}\")\n",
    "print(f\"Train Samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Val Samples: {len(val_loader.dataset)}\")\n",
    "print(f\"Test Samples: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d7d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim=input_dim).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.training['learning_rate'])\n",
    "\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a0207",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = config.training['epochs']\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_aucs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for X_batch, y_batch in progress_bar:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device).float().unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device).float().unsqueeze(1)\n",
    "            \n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            probs = torch.sigmoid(outputs)\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_metrics = calculate_metrics(np.array(all_labels), np.array(all_probs))\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_aucs.append(val_metrics['auc'])\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val AUC: {val_metrics['auc']:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeca9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(range(1, epochs+1), train_losses, label='Train Loss', marker='o')\n",
    "axes[0].plot(range(1, epochs+1), val_losses, label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Baseline Model: Training Progress')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(range(1, epochs+1), val_aucs, label='Val AUC', marker='o', color='green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('AUC')\n",
    "axes[1].set_title('Validation AUC')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        \n",
    "        all_probs.extend(probs.flatten())\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "all_probs = np.array(all_probs)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "test_metrics = calculate_metrics(all_labels, all_probs)\n",
    "\n",
    "print(\"Baseline Model Test Results:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"  {metric.upper()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd429532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(fpr, tpr, lw=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', lw=2, label='Random')\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve - Baseline Model')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(recall, precision, lw=2, label=f'PR (AUC = {pr_auc:.3f})')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe72aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../reports/results/checkpoints', exist_ok=True)\n",
    "torch.save(model.state_dict(), '../reports/results/checkpoints/baseline_model.pth')\n",
    "print(\"✓ Model saved to: reports/results/checkpoints/baseline_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
